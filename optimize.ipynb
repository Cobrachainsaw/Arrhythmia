{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import wfdb\n",
    "import torch\n",
    "import os\n",
    "from pathlib import Path\n",
    "from collections import Counter\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import re\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader, random_split, WeightedRandomSampler\n",
    "from collections import Counter\n",
    "import random\n",
    "from mealpy.swarm_based.AO import OriginalAO\n",
    "from torch.nn.functional import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = Path('C:/Users/vinay/Downloads/mit-bih-arrhythmia-database-1.0.0/mit-bih-arrhythmia-database-1.0.0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_files=[]\n",
    "annot_files=[]\n",
    "for file in os.listdir(file_path):\n",
    "    if('.dat' in file):\n",
    "        data_files.append(file[:-4])\n",
    "    elif('.atr' in file):\n",
    "        annot_files.append(file[:-4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_signals = []\n",
    "all_labels = []\n",
    "\n",
    "for i in range(48):\n",
    "    data, field = wfdb.rdsamp(os.path.join(file_path, data_files[i]))\n",
    "    data = data[:, 0]\n",
    "    \n",
    "    annot = wfdb.rdann(os.path.join(file_path, annot_files[i]), 'atr')\n",
    "    segmented_signals = [data[max(0, peak - 100):min(len(data), peak + 100)] for peak in annot.sample]\n",
    "    \n",
    "    segmented_array = np.array([\n",
    "        np.pad(signal, (0, 200 - len(signal)), mode='edge') if len(signal) < 200 else signal\n",
    "        for signal in segmented_signals\n",
    "    ])\n",
    "    \n",
    "    labels = annot.symbol[:len(segmented_array)]  \n",
    "\n",
    "    all_signals.append(segmented_array)\n",
    "    all_labels.append(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Signal Shape: (112647, 200)\n",
      "Total Labels: 112647\n"
     ]
    }
   ],
   "source": [
    "all_signals = np.concatenate(all_signals, axis=0)\n",
    "all_labels = np.concatenate(all_labels, axis=0)\n",
    "\n",
    "print(f\"Final Signal Shape: {all_signals.shape}\")  # (Total Samples, 200)\n",
    "print(f\"Total Labels: {len(all_labels)}\")  # Should match number of signals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "char_to_int = {}\n",
    "count = 0 \n",
    "\n",
    "for file in annot_files:\n",
    "    path_file = os.path.join(file_path, file)\n",
    "    annotation = wfdb.rdann(path_file, 'atr') \n",
    "    \n",
    "    for symbol in annotation.symbol:\n",
    "        if symbol not in char_to_int: \n",
    "            char_to_int[symbol] = count\n",
    "            count += 1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered Signal Shape: (112647, 200)\n",
      "Filtered Labels Shape: (112647,)\n"
     ]
    }
   ],
   "source": [
    "# Convert symbolic labels to numerical classes\n",
    "numeric_labels = np.array([char_to_int[label] for label in all_labels if label in char_to_int])\n",
    "\n",
    "# Remove signals that don't have a mapped label\n",
    "valid_indices = [i for i, label in enumerate(all_labels) if label in char_to_int]\n",
    "filtered_signals = all_signals[valid_indices]\n",
    "\n",
    "print(f\"Filtered Signal Shape: {filtered_signals.shape}\")\n",
    "print(f\"Filtered Labels Shape: {numeric_labels.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ECGDataset(Dataset):\n",
    "    def __init__(self, signals, labels):\n",
    "        # Reshape signals to (num_samples, 1, sequence_length) to add channel dim\n",
    "        self.data = torch.tensor(signals, dtype=torch.float32).unsqueeze(1)  \n",
    "        self.labels = torch.tensor(labels, dtype=torch.long)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.data[idx], self.labels[idx]\n",
    "\n",
    "# Create dataset\n",
    "ecg_dataset = ECGDataset(filtered_signals, numeric_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split dataset into training (80%), validation (10%), and test (10%)\n",
    "total_samples = len(ecg_dataset)\n",
    "train_size = int(0.8 * total_samples)\n",
    "val_size = int(0.1 * total_samples)\n",
    "test_size = total_samples - train_size - val_size  # Ensures exact split\n",
    "\n",
    "train_dataset, val_dataset, test_dataset = random_split(ecg_dataset, [train_size, val_size, test_size])\n",
    "\n",
    "# Compute class weights for balanced training sampling\n",
    "label_counts = Counter(numeric_labels)\n",
    "total_samples = sum(label_counts.values())\n",
    "class_weights = {label: total_samples / count for label, count in label_counts.items()}\n",
    "\n",
    "# Assign sample weights based on class distribution\n",
    "train_labels = [train_dataset[i][1].item() for i in range(len(train_dataset))]  # Extract labels from training set\n",
    "sample_weights = np.array([class_weights[label] for label in train_labels])\n",
    "\n",
    "# Convert to torch tensor\n",
    "sample_weights = torch.tensor(sample_weights, dtype=torch.float32)\n",
    "\n",
    "# Weighted sampler for balanced training\n",
    "sampler = WeightedRandomSampler(sample_weights, num_samples=len(sample_weights), replacement=True)\n",
    "\n",
    "# Create DataLoaders\n",
    "batch_size = 32\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, sampler=sampler)  # Balanced training\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)  # No sampler for validation\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)  # No sampler for testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HybridModel(nn.Module):\n",
    "    def __init__(self, config, num_classes):\n",
    "        super(HybridModel, self).__init__()\n",
    "\n",
    "        # Extract hyperparameters from config\n",
    "        feature_extractor = config[8]  # CNN (0) or RCNN (1)\n",
    "        sequence_model = config[9]  # BiLSTM (0) or GRU (1)\n",
    "        num_cnn_layers = int(config[0])\n",
    "        num_rnn_layers = int(config[1])\n",
    "        dropout = config[3]\n",
    "        initial_filters = 2 ** int(config[4])  # Convert to power of 2\n",
    "        initial_kernel = int(config[5])  # Initial kernel size\n",
    "        stride = int(config[6])\n",
    "        initial_hidden_size = 2 ** int(config[10])  # Convert to power of 2\n",
    "\n",
    "        # ðŸŸ¢ Convolutional Feature Extractor (CNN Layers)\n",
    "        self.conv_layers = nn.ModuleList()\n",
    "        num_filters = initial_filters\n",
    "        kernel_size = initial_kernel\n",
    "        in_channels = 1  # ECG has 1 channel\n",
    "\n",
    "        for _ in range(num_cnn_layers):\n",
    "            kernel_size = max(2, min(kernel_size, in_channels))  # Ensure kernel size is valid\n",
    "            stride = min(stride, kernel_size)  # Ensure stride is not larger than kernel\n",
    "            padding = max(0, (kernel_size - stride) // 2)  # Ensure non-negative padding\n",
    "            \n",
    "            self.conv_layers.append(nn.Conv1d(in_channels, num_filters, kernel_size, stride=stride, padding=padding))\n",
    "            self.conv_layers.append(nn.BatchNorm1d(num_filters))\n",
    "            self.conv_layers.append(nn.ReLU())\n",
    "            self.conv_layers.append(nn.Dropout(dropout))\n",
    "\n",
    "            in_channels = num_filters  # Update for next layer\n",
    "            num_filters = min(256, num_filters * 2)  # Cap filters at 256\n",
    "            kernel_size = max(3, kernel_size - 1)  # Decrease kernel size\n",
    "\n",
    "        # ðŸŸ¢ Handle RCNN (CNN + 1 LSTM/GRU Layer if enabled)\n",
    "        self.use_rcnn = feature_extractor == 1\n",
    "        rnn_input_size = in_channels  # Ensure input size matches CNN output\n",
    "\n",
    "        if self.use_rcnn:\n",
    "            self.rnn_layers_rcnn = nn.ModuleList()\n",
    "            hidden_size = initial_hidden_size\n",
    "\n",
    "            # RCNN should contain ONLY ONE LSTM/GRU layer\n",
    "            rnn_layer = (nn.LSTM if sequence_model == 0 else nn.GRU)(\n",
    "                rnn_input_size, hidden_size, bidirectional=True, batch_first=True\n",
    "            )\n",
    "            self.rnn_layers_rcnn.append(rnn_layer)\n",
    "            self.rnn_layers_rcnn.append(nn.Dropout(dropout))\n",
    "\n",
    "            # Update input size for the next LSTM/GRU layers\n",
    "            rnn_input_size = hidden_size * 2  # Account for bidirectional RNN\n",
    "\n",
    "        # ðŸŸ¢ Sequence Model (BiLSTM or GRU)\n",
    "        self.rnn_layers = nn.ModuleList()\n",
    "        hidden_size = initial_hidden_size\n",
    "\n",
    "        for _ in range(num_rnn_layers):\n",
    "            rnn_layer = (nn.LSTM if sequence_model == 0 else nn.GRU)(\n",
    "                rnn_input_size, hidden_size, bidirectional=True, batch_first=True\n",
    "            )\n",
    "            self.rnn_layers.append(rnn_layer)\n",
    "            self.rnn_layers.append(nn.Dropout(dropout))\n",
    "\n",
    "            # Update input size for next layers\n",
    "            rnn_input_size = hidden_size * 2  # Account for bidirectional RNN\n",
    "            hidden_size = max(16, hidden_size // 2)  # Reduce hidden size\n",
    "\n",
    "        # ðŸŸ¢ Fully Connected Layers\n",
    "        self.global_pool = nn.AdaptiveAvgPool1d(1)  # Reduce time dimension to 1\n",
    "        self.fc = nn.Linear(rnn_input_size, rnn_input_size // 2)  # Use dynamic size\n",
    "        self.output_layer = nn.Linear(rnn_input_size // 2, num_classes)  # Final layer\n",
    "\n",
    "        # ðŸŸ¢ Initialize weights\n",
    "        self._initialize_weights()\n",
    "\n",
    "    def forward(self, x):\n",
    "        # ðŸŸ¢ CNN Feature Extraction\n",
    "        for layer in self.conv_layers:\n",
    "            x = layer(x)\n",
    "\n",
    "        x = x.permute(0, 2, 1)  # (Batch, TimeSteps, Features)\n",
    "\n",
    "        # ðŸŸ¢ Handle RCNN (Reshape CNN output for RNN)\n",
    "        if self.use_rcnn:            \n",
    "            for layer in self.rnn_layers_rcnn:\n",
    "                if isinstance(layer, (nn.LSTM, nn.GRU)):\n",
    "                    x, _ = layer(x)  # Apply LSTM/GRU\n",
    "                else:\n",
    "                    x = layer(x)  # Apply Dropout\n",
    "\n",
    "        for layer in self.rnn_layers:\n",
    "            if isinstance(layer, (nn.LSTM, nn.GRU)):\n",
    "                x, _ = layer(x)  # Get only output\n",
    "            else:\n",
    "                x = layer(x)  # Apply Dropout\n",
    "\n",
    "        # ðŸŸ¢ Global Pooling & Fully Connected Layers\n",
    "        x = x.permute(0, 2, 1)  # (Batch, Features, TimeSteps)\n",
    "        x = self.global_pool(x)  # (Batch, Features, 1)\n",
    "        x = x.squeeze(-1)  # (Batch, Features)\n",
    "\n",
    "        x = F.relu(self.fc(x))\n",
    "        x = self.output_layer(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "    def _initialize_weights(self):\n",
    "        \"\"\"Initialize weights using Xavier initialization.\"\"\"\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv1d) or isinstance(m, nn.Linear):\n",
    "                nn.init.xavier_uniform_(m.weight)\n",
    "                if m.bias is not None:\n",
    "                    nn.init.zeros_(m.bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HybridModel(\n",
       "  (conv_layers): ModuleList(\n",
       "    (0): Conv1d(1, 128, kernel_size=(2,), stride=(2,))\n",
       "    (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Dropout(p=0.3707, inplace=False)\n",
       "    (4): Conv1d(128, 256, kernel_size=(3,), stride=(2,))\n",
       "    (5): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (6): ReLU()\n",
       "    (7): Dropout(p=0.3707, inplace=False)\n",
       "    (8): Conv1d(256, 256, kernel_size=(3,), stride=(2,))\n",
       "    (9): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (10): ReLU()\n",
       "    (11): Dropout(p=0.3707, inplace=False)\n",
       "  )\n",
       "  (rnn_layers_rcnn): ModuleList(\n",
       "    (0): GRU(256, 256, batch_first=True, bidirectional=True)\n",
       "    (1): Dropout(p=0.3707, inplace=False)\n",
       "  )\n",
       "  (rnn_layers): ModuleList(\n",
       "    (0): GRU(512, 256, batch_first=True, bidirectional=True)\n",
       "    (1): Dropout(p=0.3707, inplace=False)\n",
       "    (2): GRU(512, 128, batch_first=True, bidirectional=True)\n",
       "    (3): Dropout(p=0.3707, inplace=False)\n",
       "    (4): GRU(256, 64, batch_first=True, bidirectional=True)\n",
       "    (5): Dropout(p=0.3707, inplace=False)\n",
       "  )\n",
       "  (global_pool): AdaptiveAvgPool1d(output_size=1)\n",
       "  (fc): Linear(in_features=128, out_features=64, bias=True)\n",
       "  (output_layer): Linear(in_features=64, out_features=23, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config = [3, 3, 0.0002, 0.3707, 7, 3, 3, 5, 1, 1, 8]\n",
    "model = HybridModel(config, 23)  # Your model initialization\n",
    "model.load_state_dict(torch.load(\"models/model_30000_30000_00002_03707_70000_30000_30000_50000_10000_10000_80000.pt\", weights_only=True))\n",
    "\n",
    "# Move model to GPU if available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FocalLoss(nn.Module):\n",
    "    def __init__(self, alpha=None, gamma=2.0, reduction='mean'):\n",
    "        super(FocalLoss, self).__init__()\n",
    "        self.alpha = alpha\n",
    "        self.gamma = gamma\n",
    "        self.reduction = reduction\n",
    "    \n",
    "    def forward(self, inputs, targets):\n",
    "        ce_loss = F.cross_entropy(inputs, targets, reduction='none')\n",
    "        pt = torch.exp(-ce_loss)\n",
    "        focal_loss = (1 - pt) ** self.gamma * ce_loss\n",
    "\n",
    "        if self.alpha is not None:\n",
    "            alpha_factor = self.alpha[targets]\n",
    "            focal_loss *= alpha_factor\n",
    "        \n",
    "        return focal_loss.mean() if self.reduction == 'mean' else focal_loss.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ContrastiveLoss(nn.Module):\n",
    "    def __init__(self, margin=1.0):\n",
    "        super(ContrastiveLoss, self).__init__()\n",
    "        self.margin = margin\n",
    "    \n",
    "    def forward(self, output1, output2, label):\n",
    "        euclidean_distance = F.pairwise_distance(output1, output2)\n",
    "        loss = (1 - label) * torch.pow(euclidean_distance, 2) + \\\n",
    "               label * torch.pow(torch.clamp(self.margin - euclidean_distance, min=0.0), 2)\n",
    "        return loss.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hard_negative_mining(model, dataloader, criterion, device):\n",
    "    model.eval()  \n",
    "    hard_samples = []\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in dataloader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "\n",
    "            loss_per_sample = criterion(outputs, labels)\n",
    "            loss_per_sample = loss_per_sample.unsqueeze(0) if loss_per_sample.dim() == 0 else loss_per_sample  \n",
    "\n",
    "            loss_mean = loss_per_sample.mean()\n",
    "            misclassified = loss_per_sample > loss_mean\n",
    "            misclassified_indices = misclassified.nonzero(as_tuple=True)[0]\n",
    "\n",
    "            for i in misclassified_indices:\n",
    "                hard_samples.append((inputs[i], labels[i]))\n",
    "\n",
    "    return hard_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, train_loader, val_loader, optimizer, criterion, contrastive_loss, num_epochs=20, device='cuda'):\n",
    "    model.to(device)\n",
    "    best_val_loss = float('inf')\n",
    "    checkpoint_path = \"best_model.pth\"\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        for inputs, labels in train_loader:\n",
    "            inputs = inputs.view(inputs.shape[0], 1, inputs.shape[-1])\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            running_loss += loss.item()\n",
    "        \n",
    "        # Hard Negative Mining every 5 epochs\n",
    "        if epoch % 5 == 0:\n",
    "            hard_samples = hard_negative_mining(model, train_loader, criterion, device)\n",
    "            if hard_samples:\n",
    "                model.train()\n",
    "                for input_hard, label_hard in hard_samples:\n",
    "                    input_hard, label_hard = input_hard.unsqueeze(0).to(device), torch.tensor([label_hard], device=device)\n",
    "                    optimizer.zero_grad()\n",
    "                    output_hard = model(input_hard)\n",
    "                    hard_loss = criterion(output_hard, label_hard)\n",
    "                    hard_loss.backward()\n",
    "                    optimizer.step()\n",
    "\n",
    "        # Validation Step\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        with torch.no_grad():\n",
    "            for val_inputs, val_labels in val_loader:\n",
    "                val_inputs, val_labels = val_inputs.to(device), val_labels.to(device)\n",
    "                val_outputs = model(val_inputs)\n",
    "                loss = criterion(val_outputs, val_labels)\n",
    "                val_loss += loss.item()\n",
    "\n",
    "        val_loss /= len(val_loader)\n",
    "        print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {running_loss/len(train_loader):.4f}, Val Loss: {val_loss:.4f}\")\n",
    "\n",
    "        # Save Best Model\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            torch.save(model.state_dict(), checkpoint_path)\n",
    "            print(\"Saved best model:\", checkpoint_path)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def aoa_optimizer(model, train_loader, val_loader, device='cuda'):\n",
    "    def fitness_function(params):\n",
    "        \"\"\" Fitness function for AOA, evaluating hyperparameters \"\"\"\n",
    "        learning_rate = params[0]\n",
    "        batch_size = int(params[1])\n",
    "        dropout_rate = params[2]\n",
    "\n",
    "        # Apply dropout rate\n",
    "        model.apply(lambda m: setattr(m, 'p', dropout_rate) if hasattr(m, 'p') else None)\n",
    "\n",
    "        # Define loss and optimizer\n",
    "        criterion = FocalLoss()\n",
    "        optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "        # Train for a few epochs\n",
    "        trained_model = train_model(model, train_loader, val_loader, optimizer, criterion, None, num_epochs=5, device=device)\n",
    "\n",
    "        # Compute validation loss\n",
    "        val_loss = 0.0\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            for inputs, labels in val_loader:\n",
    "                inputs, labels = inputs.to(device), labels.to(device)\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, labels)\n",
    "                val_loss += loss.item()\n",
    "        return val_loss / len(val_loader)\n",
    "\n",
    "    # Define AOA parameters\n",
    "    problem_dict = {\n",
    "        \"fit_func\": fitness_function,\n",
    "        \"lb\": [0.0001, 16, 0.2],  # Lower bounds [Learning Rate, Batch Size, Dropout]\n",
    "        \"ub\": [0.002, 64, 0.5],   # Upper bounds [Learning Rate, Batch Size, Dropout]\n",
    "        \"minmax\": \"min\",\n",
    "        \"log_to\": None\n",
    "    }\n",
    "\n",
    "    # Run AOA\n",
    "    optimizer = OriginalAO(epoch=10, pop_size=10)\n",
    "    best_params, best_fitness = optimizer.solve(problem_dict)\n",
    "\n",
    "    print(f\"Best Hyperparameters Found: {best_params}, Best Validation Loss: {best_fitness}\")\n",
    "\n",
    "    return best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_pipeline(model, train_loader, val_loader, aoa_optimizer, device='cuda'):\n",
    "    config = [3, 3, 0.0002, 0.3707, 7, 3, 3, 5, 1, 1, 8]\n",
    "    model = HybridModel(config, 23)\n",
    "    checkpoint_path = \"models/model_30000_30000_00002_03707_70000_30000_30000_50000_10000_10000_80000.pt\"\n",
    "\n",
    "    # Load Model if Checkpoint Exists\n",
    "    if os.path.exists(checkpoint_path):\n",
    "        model.load_state_dict(torch.load(checkpoint_path, weights_only=True, map_location=device))\n",
    "        print(\"Loaded model from checkpoint:\", checkpoint_path)\n",
    "\n",
    "    # Compute Class Weights for Focal Loss\n",
    "    class_counts = Counter(train_loader.dataset.labels.numpy())\n",
    "    total_samples = sum(class_counts.values())\n",
    "    class_weights = {label: total_samples / count for label, count in class_counts.items()}\n",
    "    alpha = torch.tensor([class_weights[i] for i in range(len(class_counts))], dtype=torch.float32).to(device)\n",
    "    \n",
    "    # Define Loss & Optimizer\n",
    "    criterion = FocalLoss(alpha=alpha)\n",
    "    contrastive_loss = ContrastiveLoss()\n",
    "    \n",
    "    # Use AOA for Hyperparameter Optimization\n",
    "    print(\"AO initializing\")\n",
    "    best_hyperparams = aoa_optimizer.optimize()  # Assuming AOA is implemented separately\n",
    "    lr = best_hyperparams[\"learning_rate\"]\n",
    "    \n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "    \n",
    "    # Train the Model\n",
    "    trained_model = train_model(model, train_loader, val_loader, optimizer, criterion, contrastive_loss, num_epochs=40, device=device)\n",
    "    \n",
    "    # Save the Best Model\n",
    "    torch.save(trained_model.state_dict(), checkpoint_path)\n",
    "    print(\"Saved best model:\", checkpoint_path)\n",
    "\n",
    "    # Load Best Model & Set to Eval for Testing\n",
    "    model.load_state_dict(torch.load(checkpoint_path, map_location=device))\n",
    "    model.eval()\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model from checkpoint: models/model_30000_30000_00002_03707_70000_30000_30000_50000_10000_10000_80000.pt\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'Subset' object has no attribute 'labels'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[21], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m trained_model \u001b[38;5;241m=\u001b[39m \u001b[43mrun_pipeline\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maoa_optimizer\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[20], line 12\u001b[0m, in \u001b[0;36mrun_pipeline\u001b[1;34m(model, train_loader, val_loader, aoa_optimizer, device)\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLoaded model from checkpoint:\u001b[39m\u001b[38;5;124m\"\u001b[39m, checkpoint_path)\n\u001b[0;32m     11\u001b[0m \u001b[38;5;66;03m# Compute Class Weights for Focal Loss\u001b[39;00m\n\u001b[1;32m---> 12\u001b[0m class_counts \u001b[38;5;241m=\u001b[39m Counter(\u001b[43mtrain_loader\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlabels\u001b[49m\u001b[38;5;241m.\u001b[39mnumpy())\n\u001b[0;32m     13\u001b[0m total_samples \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msum\u001b[39m(class_counts\u001b[38;5;241m.\u001b[39mvalues())\n\u001b[0;32m     14\u001b[0m class_weights \u001b[38;5;241m=\u001b[39m {label: total_samples \u001b[38;5;241m/\u001b[39m count \u001b[38;5;28;01mfor\u001b[39;00m label, count \u001b[38;5;129;01min\u001b[39;00m class_counts\u001b[38;5;241m.\u001b[39mitems()}\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'Subset' object has no attribute 'labels'"
     ]
    }
   ],
   "source": [
    "trained_model = run_pipeline(model, train_loader, val_loader, aoa_optimizer)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
