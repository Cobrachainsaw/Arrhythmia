{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'mealpy.evolutionary_based.RKO'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[24], line 21\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mcollections\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Counter\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mrandom\u001b[39;00m\n\u001b[1;32m---> 21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmealpy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mevolutionary_based\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mRKO\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m OriginalRKO\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmealpy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mswarm_based\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mAO\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m OriginalAO\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmealpy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbio_based\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mPOA\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m OriginalPOA\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'mealpy.evolutionary_based.RKO'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import wfdb\n",
    "import torch\n",
    "import os\n",
    "from pathlib import Path\n",
    "from collections import Counter\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import re\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torch.utils.data.sampler import WeightedRandomSampler\n",
    "from collections import Counter\n",
    "import random\n",
    "from mealpy.evolutionary_based.RKO import OriginalRKO\n",
    "from mealpy.swarm_based.AO import OriginalAO\n",
    "from mealpy.bio_based.POA import OriginalPOA\n",
    "from torch.nn.functional import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = Path('C:/Users/vinay/Downloads/mit-bih-arrhythmia-database-1.0.0/mit-bih-arrhythmia-database-1.0.0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_files=[]\n",
    "annot_files=[]\n",
    "for file in os.listdir(file_path):\n",
    "    if('.dat' in file):\n",
    "        data_files.append(file[:-4])\n",
    "    elif('.atr' in file):\n",
    "        annot_files.append(file[:-4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_signals = []\n",
    "all_labels = []\n",
    "\n",
    "for i in range(48):\n",
    "    data, field = wfdb.rdsamp(os.path.join(file_path, data_files[i]))\n",
    "    data = data[:, 0]\n",
    "    \n",
    "    annot = wfdb.rdann(os.path.join(file_path, annot_files[i]), 'atr')\n",
    "    segmented_signals = [data[max(0, peak - 100):min(len(data), peak + 100)] for peak in annot.sample]\n",
    "    \n",
    "    segmented_array = np.array([\n",
    "        np.pad(signal, (0, 200 - len(signal)), mode='edge') if len(signal) < 200 else signal\n",
    "        for signal in segmented_signals\n",
    "    ])\n",
    "    \n",
    "    labels = annot.symbol[:len(segmented_array)]  \n",
    "\n",
    "    all_signals.append(segmented_array)\n",
    "    all_labels.append(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Signal Shape: (112647, 200)\n",
      "Total Labels: 112647\n"
     ]
    }
   ],
   "source": [
    "all_signals = np.concatenate(all_signals, axis=0)\n",
    "all_labels = np.concatenate(all_labels, axis=0)\n",
    "\n",
    "print(f\"Final Signal Shape: {all_signals.shape}\")  # (Total Samples, 200)\n",
    "print(f\"Total Labels: {len(all_labels)}\")  # Should match number of signals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "char_to_int = {}\n",
    "count = 0 \n",
    "\n",
    "for file in annot_files:\n",
    "    path_file = os.path.join(file_path, file)\n",
    "    annotation = wfdb.rdann(path_file, 'atr') \n",
    "    \n",
    "    for symbol in annotation.symbol:\n",
    "        if symbol not in char_to_int: \n",
    "            char_to_int[symbol] = count\n",
    "            count += 1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered Signal Shape: (112647, 200)\n",
      "Filtered Labels Shape: (112647,)\n"
     ]
    }
   ],
   "source": [
    "# Convert symbolic labels to numerical classes\n",
    "numeric_labels = np.array([char_to_int[label] for label in all_labels if label in char_to_int])\n",
    "\n",
    "# Remove signals that don't have a mapped label\n",
    "valid_indices = [i for i, label in enumerate(all_labels) if label in char_to_int]\n",
    "filtered_signals = all_signals[valid_indices]\n",
    "\n",
    "print(f\"Filtered Signal Shape: {filtered_signals.shape}\")\n",
    "print(f\"Filtered Labels Shape: {numeric_labels.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ECGDataset(Dataset):\n",
    "    def __init__(self, signals, labels):\n",
    "        # Reshape signals to (num_samples, 1, sequence_length) to add channel dim\n",
    "        self.data = torch.tensor(signals, dtype=torch.float32).unsqueeze(1)  \n",
    "        self.labels = torch.tensor(labels, dtype=torch.long)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.data[idx], self.labels[idx]\n",
    "\n",
    "# Create dataset\n",
    "ecg_dataset = ECGDataset(filtered_signals, numeric_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count label occurrences\n",
    "label_counts = Counter(numeric_labels)\n",
    "total_samples = sum(label_counts.values())\n",
    "\n",
    "# Compute class weights (inversely proportional to frequency)\n",
    "class_weights = {label: total_samples / count for label, count in label_counts.items()}\n",
    "sample_weights = np.array([class_weights[label] for label in numeric_labels])\n",
    "\n",
    "# Convert to torch tensor\n",
    "sample_weights = torch.tensor(sample_weights, dtype=torch.float32)\n",
    "sampler = WeightedRandomSampler(sample_weights, num_samples=len(sample_weights), replacement=True)\n",
    "\n",
    "# Create DataLoader with Balanced Sampler\n",
    "batch_size = 32\n",
    "balanced_dataloader = DataLoader(ecg_dataset, batch_size=batch_size, sampler=sampler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HybridModel(nn.Module):\n",
    "    def __init__(self, config, num_classes):\n",
    "        super(HybridModel, self).__init__()\n",
    "\n",
    "        # Extract hyperparameters from config\n",
    "        feature_extractor = config[8]  # CNN (0) or RCNN (1)\n",
    "        sequence_model = config[9]  # BiLSTM (0) or GRU (1)\n",
    "        num_cnn_layers = int(config[0])\n",
    "        num_rnn_layers = int(config[1])\n",
    "        dropout = config[3]\n",
    "        initial_filters = 2 ** int(config[4])  # Convert to power of 2\n",
    "        initial_kernel = int(config[5])  # Initial kernel size\n",
    "        stride = int(config[6])\n",
    "        initial_hidden_size = 2 ** int(config[10])  # Convert to power of 2\n",
    "\n",
    "        # ðŸŸ¢ Convolutional Feature Extractor (CNN Layers)\n",
    "        self.conv_layers = nn.ModuleList()\n",
    "        num_filters = initial_filters\n",
    "        kernel_size = initial_kernel\n",
    "        in_channels = 1  # ECG has 1 channel\n",
    "\n",
    "        for _ in range(num_cnn_layers):\n",
    "            kernel_size = max(2, min(kernel_size, in_channels))  # Ensure kernel size is valid\n",
    "            stride = min(stride, kernel_size)  # Ensure stride is not larger than kernel\n",
    "            padding = max(0, (kernel_size - stride) // 2)  # Ensure non-negative padding\n",
    "            \n",
    "            self.conv_layers.append(nn.Conv1d(in_channels, num_filters, kernel_size, stride=stride, padding=padding))\n",
    "            self.conv_layers.append(nn.BatchNorm1d(num_filters))\n",
    "            self.conv_layers.append(nn.ReLU())\n",
    "            self.conv_layers.append(nn.Dropout(dropout))\n",
    "\n",
    "            in_channels = num_filters  # Update for next layer\n",
    "            num_filters = min(256, num_filters * 2)  # Cap filters at 256\n",
    "            kernel_size = max(3, kernel_size - 1)  # Decrease kernel size\n",
    "\n",
    "        # ðŸŸ¢ Handle RCNN (CNN + 1 LSTM/GRU Layer if enabled)\n",
    "        self.use_rcnn = feature_extractor == 1\n",
    "        rnn_input_size = in_channels  # Ensure input size matches CNN output\n",
    "\n",
    "        if self.use_rcnn:\n",
    "            self.rnn_layers_rcnn = nn.ModuleList()\n",
    "            hidden_size = initial_hidden_size\n",
    "\n",
    "            # RCNN should contain ONLY ONE LSTM/GRU layer\n",
    "            rnn_layer = (nn.LSTM if sequence_model == 0 else nn.GRU)(\n",
    "                rnn_input_size, hidden_size, bidirectional=True, batch_first=True\n",
    "            )\n",
    "            self.rnn_layers_rcnn.append(rnn_layer)\n",
    "            self.rnn_layers_rcnn.append(nn.Dropout(dropout))\n",
    "\n",
    "            # Update input size for the next LSTM/GRU layers\n",
    "            rnn_input_size = hidden_size * 2  # Account for bidirectional RNN\n",
    "\n",
    "        # ðŸŸ¢ Sequence Model (BiLSTM or GRU)\n",
    "        self.rnn_layers = nn.ModuleList()\n",
    "        hidden_size = initial_hidden_size\n",
    "\n",
    "        for _ in range(num_rnn_layers):\n",
    "            rnn_layer = (nn.LSTM if sequence_model == 0 else nn.GRU)(\n",
    "                rnn_input_size, hidden_size, bidirectional=True, batch_first=True\n",
    "            )\n",
    "            self.rnn_layers.append(rnn_layer)\n",
    "            self.rnn_layers.append(nn.Dropout(dropout))\n",
    "\n",
    "            # Update input size for next layers\n",
    "            rnn_input_size = hidden_size * 2  # Account for bidirectional RNN\n",
    "            hidden_size = max(16, hidden_size // 2)  # Reduce hidden size\n",
    "\n",
    "        # ðŸŸ¢ Fully Connected Layers\n",
    "        self.global_pool = nn.AdaptiveAvgPool1d(1)  # Reduce time dimension to 1\n",
    "        self.fc = nn.Linear(rnn_input_size, rnn_input_size // 2)  # Use dynamic size\n",
    "        self.output_layer = nn.Linear(rnn_input_size // 2, num_classes)  # Final layer\n",
    "\n",
    "        # ðŸŸ¢ Initialize weights\n",
    "        self._initialize_weights()\n",
    "\n",
    "    def forward(self, x):\n",
    "        # ðŸŸ¢ CNN Feature Extraction\n",
    "        for layer in self.conv_layers:\n",
    "            x = layer(x)\n",
    "\n",
    "        x = x.permute(0, 2, 1)  # (Batch, TimeSteps, Features)\n",
    "\n",
    "        # ðŸŸ¢ Handle RCNN (Reshape CNN output for RNN)\n",
    "        if self.use_rcnn:            \n",
    "            for layer in self.rnn_layers_rcnn:\n",
    "                if isinstance(layer, (nn.LSTM, nn.GRU)):\n",
    "                    x, _ = layer(x)  # Apply LSTM/GRU\n",
    "                else:\n",
    "                    x = layer(x)  # Apply Dropout\n",
    "\n",
    "        for layer in self.rnn_layers:\n",
    "            if isinstance(layer, (nn.LSTM, nn.GRU)):\n",
    "                x, _ = layer(x)  # Get only output\n",
    "            else:\n",
    "                x = layer(x)  # Apply Dropout\n",
    "\n",
    "        # ðŸŸ¢ Global Pooling & Fully Connected Layers\n",
    "        x = x.permute(0, 2, 1)  # (Batch, Features, TimeSteps)\n",
    "        x = self.global_pool(x)  # (Batch, Features, 1)\n",
    "        x = x.squeeze(-1)  # (Batch, Features)\n",
    "\n",
    "        x = F.relu(self.fc(x))\n",
    "        x = self.output_layer(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "    def _initialize_weights(self):\n",
    "        \"\"\"Initialize weights using Xavier initialization.\"\"\"\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv1d) or isinstance(m, nn.Linear):\n",
    "                nn.init.xavier_uniform_(m.weight)\n",
    "                if m.bias is not None:\n",
    "                    nn.init.zeros_(m.bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = [3, 3, 0.0002, 0.3707, 7, 3, 3, 5, 1, 1, 8]\n",
    "model = HybridModel(config, 23)\n",
    "\n",
    "# Load the model weights\n",
    "model.load_state_dict(torch.load(\"models/model_30000_30000_00002_03707_70000_30000_30000_50000_10000_10000_80000.pt\", weights_only=True))\n",
    "model.eval()  # Set to evaluation mode\n",
    "\n",
    "# Step 3: Load test dataset (only inputs)\n",
    "test_loader = torch.utils.data.DataLoader(balanced_dataloader, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Focal Loss\n",
    "class FocalLoss(nn.Module):\n",
    "    def __init__(self, alpha=None, gamma=2.0, reduction='mean'):\n",
    "        super(FocalLoss, self).__init__()\n",
    "        self.alpha = alpha\n",
    "        self.gamma = gamma\n",
    "        self.reduction = reduction\n",
    "    \n",
    "    def forward(self, inputs, targets):\n",
    "        ce_loss = F.cross_entropy(inputs, targets, reduction='none')\n",
    "        pt = torch.exp(-ce_loss)  # Probabilities of correct class\n",
    "        focal_loss = (1 - pt) ** self.gamma * ce_loss\n",
    "        \n",
    "        if self.alpha is not None:\n",
    "            alpha_factor = self.alpha[targets]\n",
    "            focal_loss *= alpha_factor\n",
    "        \n",
    "        if self.reduction == 'mean':\n",
    "            return focal_loss.mean()\n",
    "        elif self.reduction == 'sum':\n",
    "            return focal_loss.sum()\n",
    "        return focal_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ContrastiveLoss(nn.Module):\n",
    "    def __init__(self, margin=1.0):\n",
    "        super(ContrastiveLoss, self).__init__()\n",
    "        self.margin = margin\n",
    "    \n",
    "    def forward(self, output1, output2, label):\n",
    "        euclidean_distance = F.pairwise_distance(output1, output2)\n",
    "        loss = (1 - label) * torch.pow(euclidean_distance, 2) + \\\n",
    "               (label) * torch.pow(torch.clamp(self.margin - euclidean_distance, min=0.0), 2)\n",
    "        return loss.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hard_negative_mining(model, dataloader, criterion, device):\n",
    "    model.eval()\n",
    "    hard_samples = []\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in dataloader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "\n",
    "            # Ensure the loss is calculated per sample\n",
    "            loss_per_sample = criterion(outputs, labels)  # Check if this returns (batch_size,)\n",
    "            if loss_per_sample.dim() == 0:  \n",
    "                loss_per_sample = loss_per_sample.unsqueeze(0)  # Ensure it's at least (1,)\n",
    "\n",
    "            loss_mean = loss_per_sample.mean()  # Compute mean loss\n",
    "            misclassified = loss_per_sample > loss_mean  # Boolean tensor (batch_size,)\n",
    "\n",
    "            # Convert misclassified to a boolean mask and use it for indexing\n",
    "            misclassified_indices = misclassified.nonzero(as_tuple=True)[0]  # Get valid indices\n",
    "            \n",
    "            for i in misclassified_indices:\n",
    "                hard_samples.append((inputs[i], labels[i]))\n",
    "\n",
    "    return hard_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train function with Focal Loss, Contrastive Learning, and Hard Negative Mining\n",
    "def train_model(model, train_loader, val_loader, optimizer, criterion, contrastive_loss, num_epochs=20, device='cuda'):\n",
    "    model.to(device)\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        for inputs, labels in train_loader:\n",
    "            inputs = inputs.view(inputs.shape[0], 1, inputs.shape[-1])\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "        \n",
    "        # Hard Negative Mining after every few epochs\n",
    "        if epoch % 5 == 0:\n",
    "            hard_samples = hard_negative_mining(model, train_loader, criterion, device)\n",
    "            if hard_samples:\n",
    "                model.train()\n",
    "                for input_hard, label_hard in hard_samples:\n",
    "                    input_hard, label_hard = input_hard.unsqueeze(0).to(device), torch.tensor([label_hard], device=device)\n",
    "                    optimizer.zero_grad()\n",
    "                    output_hard = model(input_hard)\n",
    "                    hard_loss = criterion(output_hard, label_hard)\n",
    "                    hard_loss.backward()\n",
    "                    optimizer.step()\n",
    "        \n",
    "        print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {running_loss/len(train_loader):.4f}\")\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final Training Pipeline\n",
    "def run_pipeline(model, train_loader, val_loader, device='cuda'):\n",
    "    class_counts = Counter(train_loader.dataset.labels.numpy())\n",
    "    total_samples = sum(class_counts.values())\n",
    "    class_weights = {label: total_samples / count for label, count in class_counts.items()}\n",
    "    alpha = torch.tensor([class_weights[i] for i in range(len(class_counts))], dtype=torch.float32).to(device)\n",
    "    \n",
    "    criterion = FocalLoss(alpha=alpha)\n",
    "    contrastive_loss = ContrastiveLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.0002)\n",
    "    \n",
    "    trained_model = train_model(model, train_loader, val_loader, optimizer, criterion, contrastive_loss, num_epochs=20, device=device)\n",
    "    return trained_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[50], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Run the pipeline\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m trained_model \u001b[38;5;241m=\u001b[39m \u001b[43mrun_pipeline\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbalanced_dataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Replace None with actual validation loader\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[47], line 12\u001b[0m, in \u001b[0;36mrun_pipeline\u001b[1;34m(model, train_loader, val_loader, device)\u001b[0m\n\u001b[0;32m      9\u001b[0m contrastive_loss \u001b[38;5;241m=\u001b[39m ContrastiveLoss()\n\u001b[0;32m     10\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m optim\u001b[38;5;241m.\u001b[39mAdam(model\u001b[38;5;241m.\u001b[39mparameters(), lr\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.0002\u001b[39m)\n\u001b[1;32m---> 12\u001b[0m trained_model \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontrastive_loss\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m20\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m trained_model\n",
      "Cell \u001b[1;32mIn[46], line 11\u001b[0m, in \u001b[0;36mtrain_model\u001b[1;34m(model, train_loader, val_loader, optimizer, criterion, contrastive_loss, num_epochs, device)\u001b[0m\n\u001b[0;32m      9\u001b[0m inputs, labels \u001b[38;5;241m=\u001b[39m inputs\u001b[38;5;241m.\u001b[39mto(device), labels\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m     10\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m---> 11\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     12\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(outputs, labels)\n\u001b[0;32m     13\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\nn\\modules\\module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\nn\\modules\\module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[37], line 94\u001b[0m, in \u001b[0;36mHybridModel.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     92\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m layer \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrnn_layers:\n\u001b[0;32m     93\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(layer, (nn\u001b[38;5;241m.\u001b[39mLSTM, nn\u001b[38;5;241m.\u001b[39mGRU)):\n\u001b[1;32m---> 94\u001b[0m         x, _ \u001b[38;5;241m=\u001b[39m \u001b[43mlayer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Get only output\u001b[39;00m\n\u001b[0;32m     95\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     96\u001b[0m         x \u001b[38;5;241m=\u001b[39m layer(x)  \u001b[38;5;66;03m# Apply Dropout\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\nn\\modules\\module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\nn\\modules\\module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\nn\\modules\\rnn.py:1139\u001b[0m, in \u001b[0;36mGRU.forward\u001b[1;34m(self, input, hx)\u001b[0m\n\u001b[0;32m   1137\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcheck_forward_args(\u001b[38;5;28minput\u001b[39m, hx, batch_sizes)\n\u001b[0;32m   1138\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m batch_sizes \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1139\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43m_VF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgru\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_flat_weights\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnum_layers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1140\u001b[0m \u001b[43m                     \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdropout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbidirectional\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbatch_first\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1141\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1142\u001b[0m     result \u001b[38;5;241m=\u001b[39m _VF\u001b[38;5;241m.\u001b[39mgru(\u001b[38;5;28minput\u001b[39m, batch_sizes, hx, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_flat_weights, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbias,\n\u001b[0;32m   1143\u001b[0m                      \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_layers, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbidirectional)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Run the pipeline\n",
    "trained_model = run_pipeline(model, balanced_dataloader, None)  # Replace None with actual validation loader"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
